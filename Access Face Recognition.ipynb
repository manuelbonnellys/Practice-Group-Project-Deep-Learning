{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b6cd8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu\n"
     ]
    }
   ],
   "source": [
    "import torch, cv2, numpy as np, os, time, sys, json, pathlib\n",
    "\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using\", device)\n",
    "\n",
    "\n",
    "mtcnn  = MTCNN(image_size=160, margin=14, post_process=True, device=device)\n",
    "embed  = InceptionResnetV1(pretrained='vggface2').eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca73040c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅  Enrolled 4 users: Can, Jeff, Owner, Riccardo\n"
     ]
    }
   ],
   "source": [
    "refs_path = pathlib.Path(\"refs\")\n",
    "refs_path.mkdir(exist_ok=True)\n",
    "\n",
    "ref_db = {}\n",
    "\n",
    "for jpg in refs_path.glob(\"*.jpg\"):\n",
    "    name          = jpg.stem\n",
    "    img_bgr       = cv2.imread(str(jpg))\n",
    "    img_rgb       = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "    face          = mtcnn(img_rgb)\n",
    "    if face is None:\n",
    "        raise ValueError(f\"No face found in {jpg.name}\")\n",
    "    vec           = embed(face.unsqueeze(0).to(device))[0]\n",
    "    ref_db[name]  = (vec / vec.norm()).cpu()\n",
    "\n",
    "np.save(\"ref_db.npy\", ref_db)\n",
    "print(f\"✅  Enrolled {len(ref_db)} users:\", \", \".join(ref_db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ec01f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC = 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen θ = 0.65\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from glob import glob\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def cosine(u, v): return float(torch.dot(u, v))\n",
    "\n",
    "y_true, y_score = [], []\n",
    "for fn in glob(\"val_pos/*.jpg\") + glob(\"val_neg/*.jpg\"):\n",
    "    img = cv2.cvtColor(cv2.imread(fn), cv2.COLOR_BGR2RGB)\n",
    "    face = mtcnn(img);  vec = embed(face.unsqueeze(0).to(device))[0]\n",
    "    vec = vec / vec.norm()\n",
    "    score = max(cosine(vec, e) for e in ref_db.values())\n",
    "    y_score.append(score)\n",
    "    y_true.append(int(\"val_pos\" in fn))\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "print(\"AUC =\", auc(fpr, tpr))\n",
    "\n",
    "plt.plot(fpr, tpr); plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(\"ROC\");\n",
    "plt.grid(); plt.show()\n",
    "\n",
    "θ = 0.65  # threshold for cosine similarity\n",
    "print(\"Chosen θ =\", θ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a913daaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manub\\AppData\\Local\\Temp\\ipykernel_17808\\1732093623.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ref_db = {k: torch.tensor(v).to(device) for k, v in ref_db.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Press ESC to quit\n",
      "✅ Owner @ 14:56:04  (sim=0.915)\n",
      "🔓  Door unlocked (simulated) for 2s\n",
      "✅ Owner @ 14:56:04  (sim=0.902)\n",
      "🔓  Door unlocked (simulated) for 2s\n",
      "✅ Owner @ 14:56:04  (sim=0.915)\n",
      "🔓  Door unlocked (simulated) for 2s\n",
      "✅ Owner @ 14:56:04  (sim=0.922)\n",
      "🔓  Door unlocked (simulated) for 2s\n",
      "✅ Owner @ 14:56:04  (sim=0.900)\n",
      "🔓  Door unlocked (simulated) for 2s\n",
      "✅ Owner @ 14:56:04  (sim=0.891)\n",
      "🔓  Door unlocked (simulated) for 2s\n",
      "✅ Owner @ 14:56:05  (sim=0.854)\n",
      "🔓  Door unlocked (simulated) for 2s\n",
      "✅ Owner @ 14:56:05  (sim=0.905)\n",
      "🔓  Door unlocked (simulated) for 2s\n",
      "✅ Owner @ 14:56:05  (sim=0.911)\n",
      "🔓  Door unlocked (simulated) for 2s\n",
      "✅ Owner @ 14:56:05  (sim=0.932)\n",
      "🔓  Door unlocked (simulated) for 2s\n",
      "✅ Owner @ 14:56:06  (sim=0.910)\n",
      "🔓  Door unlocked (simulated) for 2s\n",
      "✅ Owner @ 14:56:06  (sim=0.891)\n",
      "🔓  Door unlocked (simulated) for 2s\n",
      "❌ Unknown face detected @ 14:56:06  (sim=0.000)\n",
      "❌ Unknown face detected @ 14:56:06  (sim=0.000)\n",
      "❌ Unknown face detected @ 14:56:06  (sim=0.000)\n",
      "❌ Unknown face detected @ 14:56:07  (sim=0.000)\n",
      "❌ Unknown face detected @ 14:56:07  (sim=0.006)\n",
      "❌ Unknown face detected @ 14:56:07  (sim=0.202)\n",
      "❌ Unknown face detected @ 14:56:07  (sim=0.234)\n",
      "❌ Unknown face detected @ 14:56:08  (sim=0.290)\n",
      "❌ Someone similar to an enrolled user detected, but not recognized. Access denied.\n",
      "❌ Unknown face detected @ 14:56:08  (sim=0.158)\n",
      "❌ Unknown face detected @ 14:56:08  (sim=0.051)\n",
      "❌ Unknown face detected @ 14:56:08  (sim=0.000)\n",
      "❌ Unknown face detected @ 14:56:09  (sim=0.000)\n",
      "❌ Unknown face detected @ 14:56:09  (sim=0.000)\n",
      "❌ Unknown face detected @ 14:56:09  (sim=0.000)\n",
      "❌ Unknown face detected @ 14:56:09  (sim=0.000)\n",
      "❌ Unknown face detected @ 14:56:10  (sim=0.179)\n",
      "❌ Unknown face detected @ 14:56:10  (sim=0.238)\n",
      "❌ Unknown face detected @ 14:56:11  (sim=0.000)\n",
      "❌ Unknown face detected @ 14:56:11  (sim=0.000)\n",
      "❌ Unknown face detected @ 14:56:11  (sim=0.000)\n",
      "❌ Unknown face detected @ 14:56:11  (sim=0.000)\n",
      "❌ Unknown face detected @ 14:56:12  (sim=0.000)\n",
      "❌ Unknown face detected @ 14:56:12  (sim=0.000)\n",
      "❌ Unknown face detected @ 14:56:12  (sim=0.000)\n",
      "❌ Unknown face detected @ 14:56:12  (sim=0.000)\n",
      "❌ Unknown face detected @ 14:56:13  (sim=0.000)\n",
      "❌ Unknown face detected @ 14:56:13  (sim=0.000)\n",
      "❌ Unknown face detected @ 14:56:13  (sim=0.000)\n",
      "❌ Unknown face detected @ 14:56:13  (sim=0.000)\n",
      "❌ Unknown face detected @ 14:56:13  (sim=0.000)\n",
      "❌ Unknown face detected @ 14:56:14  (sim=0.000)\n",
      "❌ Unknown face detected @ 14:56:14  (sim=0.000)\n",
      "❌ Unknown face detected @ 14:56:14  (sim=0.000)\n",
      "❌ Unknown face detected @ 14:56:14  (sim=0.000)\n",
      "❌ Unknown face detected @ 14:56:15  (sim=0.000)\n",
      "❌ Unknown face detected @ 14:56:15  (sim=0.000)\n",
      "❌ Unknown face detected @ 14:56:15  (sim=0.000)\n",
      "✅ Riccardo @ 14:56:15  (sim=0.662)\n",
      "🔓  Door unlocked (simulated) for 2s\n",
      "✅ Riccardo @ 14:56:16  (sim=0.787)\n",
      "🔓  Door unlocked (simulated) for 2s\n",
      "✅ Riccardo @ 14:56:17  (sim=0.788)\n",
      "🔓  Door unlocked (simulated) for 2s\n",
      "✅ Riccardo @ 14:56:17  (sim=0.774)\n",
      "🔓  Door unlocked (simulated) for 2s\n",
      "❌ Unknown face detected @ 14:56:18  (sim=0.000)\n",
      "❌ Unknown face detected @ 14:56:18  (sim=0.000)\n",
      "❌ Unknown face detected @ 14:56:18  (sim=0.000)\n",
      "❌ Unknown face detected @ 14:56:18  (sim=0.000)\n",
      "❌ Unknown face detected @ 14:56:18  (sim=0.000)\n",
      "❌ Unknown face detected @ 14:56:18  (sim=0.000)\n",
      "✅ Owner @ 14:56:19  (sim=0.715)\n",
      "🔓  Door unlocked (simulated) for 2s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 50\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m     49\u001b[39m     ok, frame = cap.read();  \u001b[38;5;28;01massert\u001b[39;00m ok\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m     user, sim = \u001b[43midentify\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m user:\n\u001b[32m     52\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m✅ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m @ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime.strftime(\u001b[33m'\u001b[39m\u001b[33m%\u001b[39m\u001b[33mH:\u001b[39m\u001b[33m%\u001b[39m\u001b[33mM:\u001b[39m\u001b[33m%\u001b[39m\u001b[33mS\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m  (sim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msim\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36midentify\u001b[39m\u001b[34m(frame_bgr)\u001b[39m\n\u001b[32m     36\u001b[39m face = mtcnn(cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB))\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m face \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[32m0.0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m vec  = \u001b[43membed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface\u001b[49m\u001b[43m.\u001b[49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m     39\u001b[39m vec  = vec / vec.norm()\n\u001b[32m     40\u001b[39m name, score = \u001b[38;5;28mmax\u001b[39m(\n\u001b[32m     41\u001b[39m     ((n, \u001b[38;5;28mfloat\u001b[39m(torch.dot(vec, e))) \u001b[38;5;28;01mfor\u001b[39;00m n, e \u001b[38;5;129;01min\u001b[39;00m ref_db.items()),\n\u001b[32m     42\u001b[39m     key=\u001b[38;5;28;01mlambda\u001b[39;00m t: t[\u001b[32m1\u001b[39m]\n\u001b[32m     43\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\manub\\.conda\\envs\\deep_learning_project\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\manub\\.conda\\envs\\deep_learning_project\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\manub\\.conda\\envs\\deep_learning_project\\Lib\\site-packages\\facenet_pytorch\\models\\inception_resnet_v1.py:291\u001b[39m, in \u001b[36mInceptionResnetV1.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    289\u001b[39m x = \u001b[38;5;28mself\u001b[39m.mixed_6a(x)\n\u001b[32m    290\u001b[39m x = \u001b[38;5;28mself\u001b[39m.repeat_2(x)\n\u001b[32m--> \u001b[39m\u001b[32m291\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmixed_7a\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    292\u001b[39m x = \u001b[38;5;28mself\u001b[39m.repeat_3(x)\n\u001b[32m    293\u001b[39m x = \u001b[38;5;28mself\u001b[39m.block8(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\manub\\.conda\\envs\\deep_learning_project\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\manub\\.conda\\envs\\deep_learning_project\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\manub\\.conda\\envs\\deep_learning_project\\Lib\\site-packages\\facenet_pytorch\\models\\inception_resnet_v1.py:177\u001b[39m, in \u001b[36mMixed_7a.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m    176\u001b[39m     x0 = \u001b[38;5;28mself\u001b[39m.branch0(x)\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     x1 = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbranch1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     x2 = \u001b[38;5;28mself\u001b[39m.branch2(x)\n\u001b[32m    179\u001b[39m     x3 = \u001b[38;5;28mself\u001b[39m.branch3(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\manub\\.conda\\envs\\deep_learning_project\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\manub\\.conda\\envs\\deep_learning_project\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\manub\\.conda\\envs\\deep_learning_project\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    218\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\manub\\.conda\\envs\\deep_learning_project\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\manub\\.conda\\envs\\deep_learning_project\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\manub\\.conda\\envs\\deep_learning_project\\Lib\\site-packages\\facenet_pytorch\\models\\inception_resnet_v1.py:30\u001b[39m, in \u001b[36mBasicConv2d.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.bn(x)\n\u001b[32m     32\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.relu(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\manub\\.conda\\envs\\deep_learning_project\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\manub\\.conda\\envs\\deep_learning_project\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\manub\\.conda\\envs\\deep_learning_project\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m460\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\manub\\.conda\\envs\\deep_learning_project\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    452\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m'\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    453\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(F.pad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode),\n\u001b[32m    454\u001b[39m                     weight, bias, \u001b[38;5;28mself\u001b[39m.stride,\n\u001b[32m    455\u001b[39m                     _pair(\u001b[32m0\u001b[39m), \u001b[38;5;28mself\u001b[39m.dilation, \u001b[38;5;28mself\u001b[39m.groups)\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    import RPi.GPIO as GPIO\n",
    "    ON_PI = True\n",
    "except (ImportError, RuntimeError):\n",
    "    ON_PI = False \n",
    "\n",
    "def setup_relay(pin=17):\n",
    "    if ON_PI:\n",
    "        GPIO.setmode(GPIO.BCM)\n",
    "        GPIO.setup(pin, GPIO.OUT, initial=GPIO.LOW)\n",
    "    return pin\n",
    "\n",
    "def pulse_relay(pin, seconds=2):\n",
    "    if ON_PI:\n",
    "        GPIO.output(pin, GPIO.HIGH)\n",
    "        time.sleep(seconds)\n",
    "        GPIO.output(pin, GPIO.LOW)\n",
    "    else:\n",
    "        print(f\"🔓  Door unlocked (simulated) for {seconds}s\")\n",
    "\n",
    "\n",
    "\n",
    "ref_db = np.load(\"ref_db.npy\", allow_pickle=True).item()\n",
    "ref_db = {k: torch.tensor(v).to(device) for k, v in ref_db.items()}\n",
    "\n",
    "relay_pin = setup_relay(pin=17)\n",
    "θ         = 0.65\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "assert cap.isOpened(), \"Camera not found\"\n",
    "\n",
    "def identify(frame_bgr):\n",
    "    face = mtcnn(cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB))\n",
    "    if face is None: return None, 0.0\n",
    "    vec  = embed(face.unsqueeze(0).to(device))[0]\n",
    "    vec  = vec / vec.norm()\n",
    "    name, score = max(\n",
    "        ((n, float(torch.dot(vec, e))) for n, e in ref_db.items()),\n",
    "        key=lambda t: t[1]\n",
    "    )\n",
    "    return (name, score) if score > θ else (None, score)\n",
    "\n",
    "print(\"▶️ Press ESC to quit\")\n",
    "try:\n",
    "    while True:\n",
    "        ok, frame = cap.read();  assert ok\n",
    "        user, sim = identify(frame)\n",
    "        if user:\n",
    "            print(f\"✅ {user} @ {time.strftime('%H:%M:%S')}  (sim={sim:.3f})\")\n",
    "            pulse_relay(relay_pin)\n",
    "        elif user is None and sim > 0.3:\n",
    "            print(f\"❌ Someone similar to an enrolled user detected, but not recognized. Access denied.\")\n",
    "        else:\n",
    "            print(f\"❌ Unknown face detected @ {time.strftime('%H:%M:%S')}  (sim={sim:.3f})\")\n",
    "        cv2.imshow(\"live\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == 27: break\n",
    "finally:\n",
    "    cap.release(); cv2.destroyAllWindows()\n",
    "    if ON_PI: GPIO.cleanup()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
